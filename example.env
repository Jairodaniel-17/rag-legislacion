# Archivo de configuración: .env
# Renombra este archivo a ".env" antes de usarlo.

# Configuración general
KMP_DUPLICATE_LIB_OK=TRUE

# ==============================================
# CONFIGURACIÓN DEL SISTEMA EN PRODUCCIÓN
# ==============================================

# ------------------------------
# Configuración de Embeddings
# ------------------------------
# Selecciona el proveedor de embeddings
# 0 = Usar HuggingFace, 1 = Usar Ollama
FLAG_EMBEDDINGS=1 

# Modelo de Embeddings
# - Si FLAG_EMBEDDINGS=0 (HuggingFace)
#   MODEL_EMBEDDINGS="sentence-transformers/all-MiniLM-L6-v2"
# - Si FLAG_EMBEDDINGS=1 (Ollama)
# - MODEL_EMBEDDINGS="nomic-embed-text"
MODEL_EMBEDDINGS="nomic-embed-text"

# Estrategia de cálculo de distancia
# Opciones: COSINE, EUCLIDEAN_DISTANCE, MAX_INNER_PRODUCT
DISTANCE_STRATEGY="COSINE"

# ------------------------------
# Configuración del LLM
# ------------------------------
# Nombre del modelo del lenguaje (LLM)
LLM_MODEL_NAME="llama-3.2-3b-preview"

# Clave de API para el proveedor de LLM
LLM_API_KEY="TU_CLAVE_DE_API_AQUÍ"

# URL base del proveedor compatible con OpenAI
LLM_BASE_URL="https://api.groq.com/openai/v1"

# Temperatura para la generación de texto
# Valores recomendados: 0.0 (determinista) a 1.0 (creativo)
LLM_TEMPERATURE=0.5

# --------------------------------------------
# Configuración específica para Ollama (opcional)
# --------------------------------------------
# Estas configuraciones solo son necesarias si FLAG_EMBEDDINGS=1.
# LLM_API_KEY="ollama"
# LLM_BASE_URL="http://localhost:11434/v1"
# LLM_MODEL_NAME="llama3.2:latest"
